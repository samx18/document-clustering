{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45686134",
   "metadata": {},
   "source": [
    "# Scaling document clustering and data deduplication with SageMaker HuggingFace and K-Means "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd318e39",
   "metadata": {},
   "source": [
    "## Installing and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd674fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb41af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a227e",
   "metadata": {},
   "source": [
    "## Data prepration \n",
    "The dataset used is a Quora dataset that has a pair of sentence with a label that classifies if the sentences are similar or different. In our example we are only in the sentences themself, so we will create a single list that includes the sentences from both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4039e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e92e41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228ef003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single list of sentences \n",
    "sentences = df['question1'].to_list()\n",
    "sentences2 = df['question2'].to_list()\n",
    "sentences.extend(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27dbb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540c0e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market in india?',\n",
       " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'How can I increase the speed of my internet connection while using a VPN?',\n",
       " 'Why am I mentally very lonely? How can I solve it?',\n",
       " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc63244",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "In this section we will a pertained sentence transformer to create embeddings for our sentences. We will use these embeddings to create our final cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca72d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3a6dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2306a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406e0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 55s, sys: 3min 58s, total: 34min 53s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_embeddings = model.encode(sentences) #create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d7e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808580, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape #check embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35fd9d",
   "metadata": {},
   "source": [
    "## SageMaker Training\n",
    "In this section we will transform the embeddings into recordIO format, shard them across S3 key and train a k-means classifier on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1959d",
   "metadata": {},
   "source": [
    "### Import packages and setup SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c502cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::967669495843:role/service-role/AmazonSageMaker-ExecutionRole-20190812T143756\n",
      "sagemaker-us-east-1-967669495843\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import KMeans \n",
    "\n",
    "sess = sagemaker.Session() #session\n",
    "role = sagemaker.get_execution_role() # get role\n",
    "region = boto3.Session().region_name #get default region\n",
    "s3_client = boto3.client(\"s3\") \n",
    "bucket = sess.default_bucket() # get default bucket\n",
    "prefix = \"sagemaker/data-dedup\"\n",
    "\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694bda6",
   "metadata": {},
   "source": [
    "### Hyperparameters and Data\n",
    "Setup up the number of clusters, training data location and the output path. The training data location is where your transformed data that is sharded by S3 keys is uploaded and the output path will be used to write your model artifacts after then end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2582bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Loaction: s3://sagemaker-us-east-1-967669495843/sagemaker/data-dedup/train/train-data\n",
      "Output Data Loaction: s3://sagemaker-us-east-1-967669495843/sagemaker/data-dedup/output\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 15000 # number of clusters\n",
    "key = 'train-data'\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "output_path=\"s3://sagemaker-us-east-1-967669495843/sagemaker/data-dedup/output\"\n",
    "print(f\"Training Data Loaction: %s\"% s3_train_data)\n",
    "print(f\"Output Data Loaction: %s\"% output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbd3ee",
   "metadata": {},
   "source": [
    "### Create Estimator and start training\n",
    "Here we create our SM estimator, specify the input and output locations and being training.We use the record_set method to convert the embeddings into recordIO and shard them by S3 key prefixes and upload it to the training data location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a7e4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    role=role,\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    k=num_clusters,\n",
    "    data_location=s3_train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4649a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 22:40:28 Starting - Starting the training job...\n",
      "2022-03-08 22:40:56 Starting - Preparing the instances for trainingProfilerReport-1646779228: InProgress\n",
      "............\n",
      "2022-03-08 22:42:53 Downloading - Downloading input data......\n",
      "2022-03-08 22:43:57 Training - Training image download completed. Training in progress..\u001b[35mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680 integration.py:636] worker started\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'true', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '768', 'force_dense': 'True', 'k': '15000'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Final configuration: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '768', 'k': '15000'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 WARNING 139672847439680] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-217-0.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-217-0.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.2.217.0', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '2'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-217-0.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-217-0.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.2.217.0', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '2'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-217-0.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.2.217.0', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '2'}\u001b[0m\n",
      "\u001b[34mProcess 35 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 47 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Using default worker.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:04 INFO 139672847439680] Create Store: dist_async\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320 integration.py:636] worker started\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'true', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '768', 'force_dense': 'True', 'k': '15000'}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Final configuration: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '768', 'k': '15000'}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 WARNING 140091126208320] Loggers have already been setup.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-2-218-185.ec2.internal', 'TRAINING_JOB_NAME': 'kmeans-2022-03-08-22-40-28-092', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:967669495843:training-job/kmeans-2022-03-08-22-40-28-092', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-ff761e30be321341d968fb3885bfd904cd3d780ed4212970adc75c162439e1a8-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.2.217.0', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '2'}\u001b[0m\n",
      "\u001b[35mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Using default worker.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:05 INFO 140091126208320] Create Store: dist_async\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] nvidia-smi: took 0.060 seconds to run.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] Setting up with params: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '768', 'k': '15000'}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] 'extra_center_factor' was set to 'auto', evaluated to 1.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:44:06 INFO 140091126208320] number of center slices 1\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] Setting up with params: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '768', 'k': '15000'}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] 'extra_center_factor' was set to 'auto', evaluated to 1.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:44:06 INFO 139672847439680] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646779448.2991965, \"EndTime\": 1646779448.299262, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Number of Batches Since Last Reset\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[2022-03-08 22:44:08.314] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 2193, \"num_examples\": 1, \"num_bytes\": 15500000}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646779448.294067, \"EndTime\": 1646779448.2941003, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-2\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Number of Batches Since Last Reset\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[2022-03-08 22:44:08.306] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 2159, \"num_examples\": 1, \"num_bytes\": 15500000}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:45:12 INFO 139672847439680] Iter 10: Short term msd 0.589291. Long term msd 0.620965\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:45:19 INFO 140091126208320] Iter 10: Short term msd 0.558866. Long term msd 0.581978\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:46:04 INFO 139672847439680] Iter 20: Short term msd 0.529643. Long term msd 0.550073\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:46:20 INFO 140091126208320] Iter 20: Short term msd 0.505752. Long term msd 0.522351\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:46:54 INFO 139672847439680] Iter 30: Short term msd 0.511141. Long term msd 0.522653\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:47:19 INFO 140091126208320] Iter 30: Short term msd 0.491200. Long term msd 0.500653\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:47:44 INFO 139672847439680] Iter 40: Short term msd 0.500216. Long term msd 0.507470\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:48:14 INFO 140091126208320] Iter 40: Short term msd 0.482448. Long term msd 0.488613\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:48:35 INFO 139672847439680] Iter 50: Short term msd 0.494162. Long term msd 0.498544\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:49:13 INFO 140091126208320] Iter 50: Short term msd 0.477886. Long term msd 0.481575\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:49:25 INFO 139672847439680] Iter 60: Short term msd 0.486094. Long term msd 0.490439\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:50:08 INFO 140091126208320] Iter 60: Short term msd 0.471634. Long term msd 0.475263\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:50:14 INFO 139672847439680] Iter 70: Short term msd 0.484562. Long term msd 0.486844\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:00 INFO 139672847439680] Iter 80: Short term msd 0.485443. Long term msd 0.485818\u001b[0m\n",
      "\u001b[34m[2022-03-08 22:51:00.883] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 412568, \"num_examples\": 81, \"num_bytes\": 1253299000}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:00 INFO 139672847439680] processed a total of 404290 examples\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:00 INFO 139672847439680] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646779448.3148608, \"EndTime\": 1646779860.9041634, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 409290.0, \"count\": 1, \"min\": 409290, \"max\": 409290}, \"Total Batches Seen\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Max Records Seen Between Resets\": {\"sum\": 404290.0, \"count\": 1, \"min\": 404290, \"max\": 404290}, \"Max Batches Seen Between Resets\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 404290.0, \"count\": 1, \"min\": 404290, \"max\": 404290}, \"Number of Batches Since Last Reset\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:00 INFO 139672847439680] #throughput_metric: host=algo-1, train throughput=979.8839336964325 records/second\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:03 INFO 140091126208320] Iter 70: Short term msd 0.469334. Long term msd 0.471552\u001b[0m\n",
      "\n",
      "2022-03-08 22:52:05 Uploading - Uploading generated training model\u001b[35m[03/08/2022 22:51:58 INFO 140091126208320] Iter 80: Short term msd 0.471598. Long term msd 0.471615\u001b[0m\n",
      "\u001b[35m[2022-03-08 22:51:58.978] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 470671, \"num_examples\": 81, \"num_bytes\": 1253299000}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:58 INFO 140091126208320] processed a total of 404290 examples\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] #progress_metric: host=algo-2, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646779448.3066614, \"EndTime\": 1646779919.0029655, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-2\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 409290.0, \"count\": 1, \"min\": 409290, \"max\": 409290}, \"Total Batches Seen\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Max Records Seen Between Resets\": {\"sum\": 404290.0, \"count\": 1, \"min\": 404290, \"max\": 404290}, \"Max Batches Seen Between Resets\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 404290.0, \"count\": 1, \"min\": 404290, \"max\": 404290}, \"Number of Batches Since Last Reset\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}}}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] #throughput_metric: host=algo-2, train throughput=858.9186644921623 records/second\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] No shrinking is required as extra_center_factor is 1.\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] gradient: cluster center took: 28.0577%, (117.266577 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] compute all data-center distances: inner product took: 26.2247%, (109.605436 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] gradient: cluster size  took: 23.4871%, (98.163544 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] predict compute msd took: 14.8815%, (62.196640 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] collect from kv store took: 2.6507%, (11.078638 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] compute all data-center distances: center norm took: 1.8969%, (7.928114 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] compute all data-center distances: point norm took: 1.0825%, (4.524450 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] gradient: one_hot took: 0.6850%, (2.863037 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] batch data loading with context took: 0.5805%, (2.426035 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] splitting centers key-value pair took: 0.3842%, (1.605668 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] update state and report convergance took: 0.0683%, (0.285284 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] predict minus dist took: 0.0009%, (0.003640 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] update set-up time took: 0.0001%, (0.000299 secs)\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] TOTAL took: 417.9473628997803\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646779446.1207497, \"EndTime\": 1646779919.1471965, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 2099.7071266174316, \"count\": 1, \"min\": 2099.7071266174316, \"max\": 2099.7071266174316}, \"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 412589.0152454376, \"count\": 1, \"min\": 412589.0152454376, \"max\": 412589.0152454376}, \"finalize.time\": {\"sum\": 87.22138404846191, \"count\": 1, \"min\": 87.22138404846191, \"max\": 87.22138404846191}, \"model.serialize.time\": {\"sum\": 55.875539779663086, \"count\": 1, \"min\": 55.875539779663086, \"max\": 55.875539779663086}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1646779919.147407, \"EndTime\": 1646779919.1478744, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 40.396690368652344, \"count\": 1, \"min\": 40.396690368652344, \"max\": 40.396690368652344}, \"totaltime\": {\"sum\": 474306.2152862549, \"count\": 1, \"min\": 474306.2152862549, \"max\": 474306.2152862549}}}\u001b[0m\n",
      "\u001b[34m[03/08/2022 22:51:59 INFO 139672847439680 integration.py:636] worker closed\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] No shrinking is required as extra_center_factor is 1.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] gradient: cluster center took: 24.1667%, (114.952589 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] compute all data-center distances: inner product took: 22.7316%, (108.126152 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] gradient: cluster size  took: 20.6407%, (98.180617 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] collect from kv store took: 15.6737%, (74.554094 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] predict compute msd took: 12.8904%, (61.314881 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] compute all data-center distances: center norm took: 1.6004%, (7.612710 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] compute all data-center distances: point norm took: 0.9375%, (4.459527 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] gradient: one_hot took: 0.5688%, (2.705495 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] batch data loading with context took: 0.4340%, (2.064332 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] splitting centers key-value pair took: 0.2988%, (1.421501 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] update state and report convergance took: 0.0565%, (0.268668 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] predict minus dist took: 0.0008%, (0.003767 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] update set-up time took: 0.0001%, (0.000357 secs)\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] TOTAL took: 475.6646890640259\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] No model is serialized on a non-master node\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646779446.1465287, \"EndTime\": 1646779919.8877594, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-2\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 2068.977117538452, \"count\": 1, \"min\": 2068.977117538452, \"max\": 2068.977117538452}, \"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 470695.9767341614, \"count\": 1, \"min\": 470695.9767341614, \"max\": 470695.9767341614}, \"finalize.time\": {\"sum\": 883.6216926574707, \"count\": 1, \"min\": 883.6216926574707, \"max\": 883.6216926574707}, \"model.serialize.time\": {\"sum\": 0.10013580322265625, \"count\": 1, \"min\": 0.10013580322265625, \"max\": 0.10013580322265625}}}\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320] Test data is not provided.\u001b[0m\n",
      "\u001b[35m[03/08/2022 22:51:59 INFO 140091126208320 integration.py:636] worker closed\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1646779919.8878736, \"EndTime\": 1646779919.8879957, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-2\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 41.960954666137695, \"count\": 1, \"min\": 41.960954666137695, \"max\": 41.960954666137695}, \"totaltime\": {\"sum\": 474288.7167930603, \"count\": 1, \"min\": 474288.7167930603, \"max\": 474288.7167930603}}}\u001b[0m\n",
      "\n",
      "2022-03-08 22:52:36 Completed - Training job completed\n",
      "ProfilerReport-1646779228: NoIssuesFound\n",
      "Training seconds: 1182\n",
      "Billable seconds: 1182\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(kmeans.record_set(sentence_embeddings)) # start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c2300",
   "metadata": {},
   "source": [
    "## Inference\n",
    "In this section we will create a SageMaker endpoint and use it to get inferences. In our case this will be a cluster id for each of the sentence embeddings in our dataset. Since we are using real time endpoints to run inference, we will split our embeddings into multiple batches of smaller size and pass these batches to the endpoint for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "443b2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split into 10000 batches, of size 81.\n"
     ]
    }
   ],
   "source": [
    "# create batches\n",
    "import numpy as np\n",
    "batches = np.array_split(sentence_embeddings, 10000)\n",
    "print(f\"data split into 10000 batches, of size {batches[0].shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313812ea",
   "metadata": {},
   "source": [
    "Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a9def80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!CPU times: user 226 ms, sys: 9.17 ms, total: 235 ms\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3665f",
   "metadata": {},
   "source": [
    "We use the `JSONDeserializer()` method from `sagemaker.deserializers` which makes it easy to work with inference results. Here we collate the results from all the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26a70cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "kmeans_predictor.deserializer = JSONDeserializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c0650c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 5.43 s, total: 2min 28s\n",
      "Wall time: 22min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_results =[]\n",
    "for batch in batches:\n",
    "    result = kmeans_predictor.predict(batch)\n",
    "    result=result[\"predictions\"]\n",
    "    for r in range(len(result)):\n",
    "        batch_results.append(result[r]['closest_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a9095eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_results) #verify inference results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b296ba",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127683c3",
   "metadata": {},
   "source": [
    "### Post Processing\n",
    "Our inference results consist of cluster id for each sentence embedding in our dataset. Here we take the results from our inference and map them to our original sentences. We also convert everything into a data frame that makes data analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4d14ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_clusters = list(map(list,zip(sentences,batch_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c57cee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>1831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>1338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>1156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>12979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>1314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cluster_id\n",
       "0  What is the step by step guide to invest in sh...      4448.0\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...      4780.0\n",
       "2  How can I increase the speed of my internet co...      3974.0\n",
       "3  Why am I mentally very lonely? How can I solve...      1831.0\n",
       "4  Which one dissolve in water quikly sugar, salt...      1338.0\n",
       "5  Astrology: I am a Capricorn Sun Cap moon and c...      1156.0\n",
       "6                                Should I buy tiago?     12979.0\n",
       "7                     How can I be a good geologist?       332.0\n",
       "8                    When do you use シ instead of し?      1314.0\n",
       "9  Motorola (company): Can I hack my Charter Moto...       219.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to data frame\n",
    "sentence_clusters_df = pd.DataFrame(sentence_clusters,columns=['text','cluster_id'])\n",
    "sentence_clusters_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89f61f",
   "metadata": {},
   "source": [
    "### Analyzing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b787a06",
   "metadata": {},
   "source": [
    "Let's check some random clusters, like here check a cluster related to investing shows good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "451934e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>How do I invest money into stock market?</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11387</th>\n",
       "      <td>What all does somebody need to know to start i...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13805</th>\n",
       "      <td>How do I invest in a share market?</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14829</th>\n",
       "      <td>How do I invest in stock market?</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789808</th>\n",
       "      <td>What is the procedure to invest in the share m...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793433</th>\n",
       "      <td>How did Rakesh Jhunjhunwala make money to inve...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798449</th>\n",
       "      <td>I am software enginner and I want to invest in...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801246</th>\n",
       "      <td>How do I invest profitably in stock market?</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803418</th>\n",
       "      <td>How do I invest money in the stock markets of ...</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  cluster_id\n",
       "0       What is the step by step guide to invest in sh...      4448.0\n",
       "11206            How do I invest money into stock market?      4448.0\n",
       "11387   What all does somebody need to know to start i...      4448.0\n",
       "13805                  How do I invest in a share market?      4448.0\n",
       "14829                    How do I invest in stock market?      4448.0\n",
       "...                                                   ...         ...\n",
       "789808  What is the procedure to invest in the share m...      4448.0\n",
       "793433  How did Rakesh Jhunjhunwala make money to inve...      4448.0\n",
       "798449  I am software enginner and I want to invest in...      4448.0\n",
       "801246        How do I invest profitably in stock market?      4448.0\n",
       "803418  How do I invest money in the stock markets of ...      4448.0\n",
       "\n",
       "[136 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clusters_df[sentence_clusters_df[\"cluster_id\"] == 4448.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031355e",
   "metadata": {},
   "source": [
    "Similarly if we pick up another cluster presumably about internet connectivity we see similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86d09a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>How can I speed up my Internet connectionn?</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>I have a Tata Photon Plus dongle for the inter...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21934</th>\n",
       "      <td>How can I speed up my Internet connection?</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44264</th>\n",
       "      <td>My upload speed in uTorrent is triple or even ...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788986</th>\n",
       "      <td>How can I boost up Internet speed or hack inte...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789231</th>\n",
       "      <td>What causes Comcast internet to be slow?</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791298</th>\n",
       "      <td>My JIOFI device is not giving speed even more ...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793570</th>\n",
       "      <td>I am paying for 20Mbps internet but getting on...</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794900</th>\n",
       "      <td>Why do I get such a slow download speed?</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  cluster_id\n",
       "2       How can I increase the speed of my internet co...      3974.0\n",
       "1918          How can I speed up my Internet connectionn?      3974.0\n",
       "5420    I have a Tata Photon Plus dongle for the inter...      3974.0\n",
       "21934          How can I speed up my Internet connection?      3974.0\n",
       "44264   My upload speed in uTorrent is triple or even ...      3974.0\n",
       "...                                                   ...         ...\n",
       "788986  How can I boost up Internet speed or hack inte...      3974.0\n",
       "789231           What causes Comcast internet to be slow?      3974.0\n",
       "791298  My JIOFI device is not giving speed even more ...      3974.0\n",
       "793570  I am paying for 20Mbps internet but getting on...      3974.0\n",
       "794900           Why do I get such a slow download speed?      3974.0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clusters_df[sentence_clusters_df[\"cluster_id\"] == 3974.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf9462",
   "metadata": {},
   "source": [
    "Even in cases for very niche subjects like  documents about the Kohinoor diamond, yields some decent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a689d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17296</th>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81998</th>\n",
       "      <td>Do you think Kohinoor was a gift from India?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131477</th>\n",
       "      <td>Will India ever get its Kohinoor diamond back?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133496</th>\n",
       "      <td>What if Kohinoor diamond comes back to India?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178151</th>\n",
       "      <td>Why England is not returning Kohinoor Diamond ...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184732</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241715</th>\n",
       "      <td>Is it possible to get Kohinoor from British ro...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263614</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313927</th>\n",
       "      <td>Was the Kohinoor really gifted to England queen?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359232</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404291</th>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421586</th>\n",
       "      <td>Why can't India get its Kohinoor diamond back?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427538</th>\n",
       "      <td>Where is Lord Krishna's diamond?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465726</th>\n",
       "      <td>Where is Lord Krishna's diamond?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486288</th>\n",
       "      <td>Did the Queen steal the Kohinoor from India or...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491808</th>\n",
       "      <td>Where is Lord Krishna's diamond?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535767</th>\n",
       "      <td>Why can't India get its Kohinoor diamond back?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537786</th>\n",
       "      <td>Why can't India get its Kohinoor diamond back?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582441</th>\n",
       "      <td>Why won't Britain return the Koh-i-Noor Diamon...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646005</th>\n",
       "      <td>Will India ever get its Kohinoor diamond back?</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718217</th>\n",
       "      <td>Did the Queen steal the Kohinoor from India or...</td>\n",
       "      <td>4780.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  cluster_id\n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...      4780.0\n",
       "17296   What would happen if the Indian government sto...      4780.0\n",
       "81998        Do you think Kohinoor was a gift from India?      4780.0\n",
       "131477     Will India ever get its Kohinoor diamond back?      4780.0\n",
       "133496      What if Kohinoor diamond comes back to India?      4780.0\n",
       "178151  Why England is not returning Kohinoor Diamond ...      4780.0\n",
       "184732  What is the story of Kohinoor (Koh-i-Noor) Dia...      4780.0\n",
       "241715  Is it possible to get Kohinoor from British ro...      4780.0\n",
       "263614  What is the story of Kohinoor (Koh-i-Noor) Dia...      4780.0\n",
       "313927   Was the Kohinoor really gifted to England queen?      4780.0\n",
       "359232  What is the story of Kohinoor (Koh-i-Noor) Dia...      4780.0\n",
       "404291  What would happen if the Indian government sto...      4780.0\n",
       "421586     Why can't India get its Kohinoor diamond back?      4780.0\n",
       "427538                   Where is Lord Krishna's diamond?      4780.0\n",
       "465726                   Where is Lord Krishna's diamond?      4780.0\n",
       "486288  Did the Queen steal the Kohinoor from India or...      4780.0\n",
       "491808                   Where is Lord Krishna's diamond?      4780.0\n",
       "535767     Why can't India get its Kohinoor diamond back?      4780.0\n",
       "537786     Why can't India get its Kohinoor diamond back?      4780.0\n",
       "582441  Why won't Britain return the Koh-i-Noor Diamon...      4780.0\n",
       "646005     Will India ever get its Kohinoor diamond back?      4780.0\n",
       "718217  Did the Queen steal the Kohinoor from India or...      4780.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clusters_df[sentence_clusters_df[\"cluster_id\"] == 4780.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a94dd",
   "metadata": {},
   "source": [
    "There are some areas where it did not perform as well. for example in cases where there were many small instances very similar documents, but the differences were still meaningful, the model ended up clustering them within the same cluster.For example, this specific cluster includes documents related to geology and other similar  and general sciences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d8c778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13674</th>\n",
       "      <td>What should I consider before becoming a chef?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17614</th>\n",
       "      <td>How do I become better at research?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21951</th>\n",
       "      <td>How does one become a scientist?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37569</th>\n",
       "      <td>I want to become an astronomer but how?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772626</th>\n",
       "      <td>My IQ level is 105 and I am of 14 years, can I...</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781888</th>\n",
       "      <td>How can I become an forensic scientist?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788732</th>\n",
       "      <td>How do I become an Opthalmologist?</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800644</th>\n",
       "      <td>How can I become an astrophysicist in India? I...</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807897</th>\n",
       "      <td>How do I become a member of the Royal Swedish ...</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  cluster_id\n",
       "7                          How can I be a good geologist?       332.0\n",
       "13674      What should I consider before becoming a chef?       332.0\n",
       "17614                 How do I become better at research?       332.0\n",
       "21951                    How does one become a scientist?       332.0\n",
       "37569             I want to become an astronomer but how?       332.0\n",
       "...                                                   ...         ...\n",
       "772626  My IQ level is 105 and I am of 14 years, can I...       332.0\n",
       "781888            How can I become an forensic scientist?       332.0\n",
       "788732                 How do I become an Opthalmologist?       332.0\n",
       "800644  How can I become an astrophysicist in India? I...       332.0\n",
       "807897  How do I become a member of the Royal Swedish ...       332.0\n",
       "\n",
       "[166 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_clusters_df[sentence_clusters_df[\"cluster_id\"] == 332.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32a8f0",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "Optionally the endpoint created to stop incurring charges. You may also want to remove files from S3 to avoid any storage charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb670ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db9118",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this example we showcased how to use HuggingFace embeddings along with SageMaker k-means algorithm for clustering similar documents and find any duplicates. This can be used as a viable approach other index based document similarity approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p37",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
